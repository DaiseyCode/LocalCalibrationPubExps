% Generated on 2025-09-11 21:13:27 from git commit d0c9b7e (dirty)

\begin{table*}[htbp]
% Note: Add \usepackage{booktabs}, \usepackage{amssymb}, \usepackage{multirow}, and \usepackage{makecell} to document preamble
\centering
\begin{tabular}{c l l c c c c c c c c c c}
\toprule
 &  &  & \multicolumn{5}{c}{Line-Level} & \multicolumn{5}{c}{Token-Level} \\
 &  &  & \multicolumn{3}{c}{Unscaled} & \multicolumn{2}{c}{Scaled} & \multicolumn{3}{c}{Unscaled} & \multicolumn{2}{c}{Scaled} \\
\cmidrule(lr){4-6}
\cmidrule(lr){7-8}
\cmidrule(lr){9-11}
\cmidrule(lr){12-13}
\mutt & Technique & Eval Dataset & BSS $\uparrow$ & ECE $\downarrow$ & AUC $\uparrow$ & BSS $\uparrow$ & ECE $\downarrow$ & BSS $\uparrow$ & ECE $\downarrow$ & AUC $\uparrow$ & BSS $\uparrow$ & ECE $\downarrow$ \\
\midrule
Qwen/Qwen2.5-Coder-7B-Instruct & Line Verbalized & HumanEval+ & 0.09 & 0.13 & 0.79 & 0.19 & 0.08 & -0.51 & 0.08 & 0.79 & 0.18 & 0.02 \\
Qwen/Qwen2.5-Coder-7B-Instruct & Line Verbalized & MBPP+ & 0.36 & 0.09 & 0.83 & 0.39 & 0.04 & 0.06 & 0.08 & 0.76 & 0.17 & 0.03 \\
Qwen/Qwen2.5-Coder-7B-Instruct & Line Verbalized & livecodebench & -0.82 & 0.46 & 0.73 & 0.12 & 0.09 & -0.31 & 0.29 & 0.66 & 0.06 & 0.07 \\
Qwen/Qwen2.5-Coder-7B-Instruct & Line Verbalized & repocod & -1.70 & 0.61 & 0.60 & 0.00 & 0.03 & -1.00 & 0.51 & 0.55 & -0.00 & 0.00 \\
Qwen/Qwen2.5-Coder-7B-Instruct & Token Prob & HumanEval+ & -0.19 & 0.16 & 0.54 & -0.01 & 0.01 & -0.08 & 0.06 & 0.51 & -0.00 & 0.00 \\
Qwen/Qwen2.5-Coder-7B-Instruct & Token Prob & MBPP+ & -0.33 & 0.26 & 0.56 & 0.01 & 0.00 & -0.19 & 0.16 & 0.51 & 0.00 & 0.00 \\
Qwen/Qwen2.5-Coder-7B-Instruct & Token Prob & livecodebench & -1.40 & 0.58 & 0.54 & 0.00 & 0.01 & -0.65 & 0.40 & 0.52 & 0.00 & 0.00 \\
Qwen/Qwen2.5-Coder-7B-Instruct & Token Prob & repocod & -2.11 & 0.67 & 0.58 & 0.01 & 0.00 & -1.22 & 0.55 & 0.50 & 0.00 & 0.00 \\
gpt-4o & Line Verbalized & HumanEval+ & 0.37 & 0.04 & 0.94 & 0.36 & 0.02 & -1.10 & 0.06 & 0.90 & 0.06 & 0.00 \\
gpt-4o & Line Verbalized & MBPP+ & 0.23 & 0.11 & 0.73 & 0.21 & 0.16 & 0.06 & 0.11 & 0.65 & 0.12 & 0.13 \\
gpt-4o & Line Verbalized & livecodebench & -0.12 & 0.23 & 0.75 & 0.16 & 0.12 & -0.07 & 0.18 & 0.73 & 0.11 & 0.09 \\
gpt-4o & Line Verbalized & repocod & -0.98 & 0.49 & 0.63 & 0.03 & 0.07 & -0.52 & 0.36 & 0.60 & 0.03 & 0.02 \\
gpt-4o & Token Prob & HumanEval+ & -0.04 & 0.04 & 0.70 & 0.01 & 0.01 & -0.35 & 0.04 & 0.66 & 0.00 & 0.00 \\
gpt-4o & Token Prob & MBPP+ & -0.19 & 0.19 & 0.60 & 0.02 & 0.00 & -0.17 & 0.15 & 0.56 & 0.00 & 0.00 \\
gpt-4o & Token Prob & livecodebench & -0.28 & 0.26 & 0.59 & 0.02 & 0.01 & -0.25 & 0.23 & 0.59 & 0.01 & 0.01 \\
gpt-4o & Token Prob & repocod & -1.20 & 0.54 & 0.63 & 0.04 & 0.03 & -0.72 & 0.42 & 0.58 & 0.01 & 0.02 \\
\bottomrule
\end{tabular}
\caption{Cross-SE Robustness with with a leave-one-out of each problem source. GPT-4o generated. Qwen 0.5B Probe.}
\label{tab:cross_se_robustness}
\end{table*}