% Generated on 2025-09-12 03:43:09 from git commit 5067cff (dirty)

\begin{table*}[htbp]
% Note: Add \usepackage{booktabs}, \usepackage{amssymb}, \usepackage{multirow}, \usepackage{makecell}, and \usepackage{graphicx} to document preamble
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{l l l c c c c c c c c c c}
\toprule
 &  &  & \multicolumn{5}{c}{Line-Level} & \multicolumn{5}{c}{Token-Level} \\
 &  &  & \multicolumn{3}{c}{Unscaled} & \multicolumn{2}{c}{Scaled} & \multicolumn{3}{c}{Unscaled} & \multicolumn{2}{c}{Scaled} \\
\cmidrule(lr){4-6}
\cmidrule(lr){7-8}
\cmidrule(lr){9-11}
\cmidrule(lr){12-13}
\mutt & Technique & Eval Dataset & BSS $\uparrow$ & ECE $\downarrow$ & AUC $\uparrow$ & BSS $\uparrow$ & ECE $\downarrow$ & BSS $\uparrow$ & ECE $\downarrow$ & AUC $\uparrow$ & BSS $\uparrow$ & ECE $\downarrow$ \\
\midrule
GPT-4o & Probe-0.5B & HumanEval+ & -0.47 & 0.13 & 0.55 & -0.00 & 0.00 & -1.28 & 0.16 & 0.59 & 0.00 & 0.00 \\
GPT-4o & Probe-0.5B & MBPP+ & 0.06 & 0.04 & 0.67 & 0.07 & 0.01 & 0.05 & 0.03 & 0.68 & 0.06 & 0.01 \\
GPT-4o & Probe-0.5B & LiveCodeBench & 0.05 & 0.05 & 0.65 & 0.07 & 0.01 & 0.04 & 0.03 & 0.64 & 0.05 & 0.01 \\
GPT-4o & Probe-0.5B & RepoCod-s & 0.06 & 0.07 & 0.66 & 0.08 & 0.01 & 0.00 & 0.08 & 0.60 & 0.03 & 0.01 \\
GPT-4o & Probe-7B & HumanEval+ & -0.42 & 0.06 & 0.55 & -0.00 & 0.00 & -0.81 & 0.09 & 0.52 & -0.00 & 0.00 \\
GPT-4o & Probe-7B & MBPP+ & -0.15 & 0.16 & 0.57 & 0.01 & 0.01 & -0.05 & 0.08 & 0.62 & 0.02 & 0.01 \\
GPT-4o & Probe-7B & LiveCodeBench & -0.03 & 0.13 & 0.65 & 0.06 & 0.02 & 0.00 & 0.09 & 0.65 & 0.06 & 0.01 \\
GPT-4o & Probe-7B & RepoCod-s & -0.07 & 0.13 & 0.63 & 0.05 & 0.02 & -0.08 & 0.14 & 0.58 & 0.02 & 0.00 \\
Qwen2.5Coder & Probe-0.5B & HumanEval+ & -0.07 & 0.14 & 0.71 & 0.08 & 0.03 & -0.64 & 0.18 & 0.68 & 0.03 & 0.01 \\
Qwen2.5Coder & Probe-0.5B & MBPP+ & 0.02 & 0.05 & 0.67 & 0.05 & 0.02 & -0.03 & 0.08 & 0.67 & 0.04 & 0.02 \\
Qwen2.5Coder & Probe-0.5B & LiveCodeBench & -0.07 & 0.22 & 0.72 & 0.14 & 0.02 & 0.03 & 0.12 & 0.68 & 0.09 & 0.02 \\
Qwen2.5Coder & Probe-0.5B & RepoCod-s & 0.01 & 0.08 & 0.63 & 0.04 & 0.02 & -0.02 & 0.07 & 0.57 & 0.01 & 0.00 \\
Qwen2.5Coder & Probe-7B & HumanEval+ & 0.20 & 0.04 & 0.78 & 0.20 & 0.02 & -0.14 & 0.08 & 0.72 & 0.07 & 0.00 \\
Qwen2.5Coder & Probe-7B & MBPP+ & 0.01 & 0.11 & 0.72 & 0.11 & 0.03 & 0.01 & 0.05 & 0.70 & 0.07 & 0.01 \\
Qwen2.5Coder & Probe-7B & LiveCodeBench & -0.01 & 0.16 & 0.72 & 0.14 & 0.02 & 0.05 & 0.10 & 0.68 & 0.10 & 0.01 \\
Qwen2.5Coder & Probe-7B & RepoCod-s & -0.15 & 0.16 & 0.57 & 0.01 & 0.00 & -0.14 & 0.16 & 0.54 & 0.00 & 0.00 \\
\bottomrule
\end{tabular}
}%
\caption{\textbf{Probing} with a leave-one-out of each dataset for each generating Model Under Test (\mutt).}
\label{tab:cross_se_robustness_probe}
\end{table*}